{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recsys_2022_msgifsr_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MSGIFSR Session Recommender\n",
        "# @author: Ivan Vrkic\n",
        "\n",
        "This notebook is set up to be run in Google Colab.\n"
      ],
      "metadata": {
        "id": "wnLqxSaO_zFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "AcdA7ch8_mgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RRYNJhKhebf",
        "outputId": "7904b5aa-0c12-4296-f498-1def09c697cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul  9 14:18:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dgl\n",
        "!pip install wandb\n",
        "!pip install dgl-cu101 \n",
        "\n",
        "!pip install gdown\n",
        "\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1Bo2PHNcGyiQJE-dldYhLXL1RgYPenv7u/view?usp=sharing\n",
        "!gdown --fuzzy https://drive.google.com/file/d/127tRcgb06QbdV7hTWRpj9K2C1xMnbFIR/view?usp=sharing\n",
        "!gdown --fuzzy https://drive.google.com/file/d/1ZLwbIHXy8-CARacsMPPzzIU10NxvcVhz/view?usp=sharing\n",
        "\n",
        "!git clone https://github.com/ivanvrkic/MSGIFSR-SessionRec-pytorch\n",
        "!cp -r /content/MSGIFSR-SessionRec-pytorch/* /content/\n",
        "\n",
        "!mkdir datasets/dressipy\n",
        "!mv test_final_sessions.csv datasets/dressipy\n",
        "!mv train_sessions.csv datasets/dressipy\n",
        "!mv train_purchases.csv datasets/dressipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOLnNjD0DLOe",
        "outputId": "bb06ab89-0449-40ca-f3d5-301ecf6f47b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgl\n",
            "  Downloading dgl-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 10.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.21-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.6.0-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 57.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 423 kB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=7f644ccd795b91c3901c50ec26a6a039dff91849960abb187d2206dfbe1477f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.6.0 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.21\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dgl-cu101\n",
            "  Downloading dgl_cu101-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (36.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 36.2 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.6.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu101) (1.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu101) (2.10)\n",
            "Installing collected packages: dgl-cu101\n",
            "Successfully installed dgl-cu101-0.6.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (4.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from gdown) (4.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown) (3.7.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Bo2PHNcGyiQJE-dldYhLXL1RgYPenv7u\n",
            "To: /content/train_sessions.csv\n",
            "100% 177M/177M [00:01<00:00, 124MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=127tRcgb06QbdV7hTWRpj9K2C1xMnbFIR\n",
            "To: /content/train_purchases.csv\n",
            "100% 37.2M/37.2M [00:00<00:00, 119MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZLwbIHXy8-CARacsMPPzzIU10NxvcVhz\n",
            "To: /content/test_final_sessions.csv\n",
            "100% 8.43M/8.43M [00:00<00:00, 65.7MB/s]\n",
            "Cloning into 'MSGIFSR-SessionRec-pytorch'...\n",
            "remote: Enumerating objects: 946, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 946 (delta 23), reused 38 (delta 10), pack-reused 888\u001b[K\n",
            "Receiving objects: 100% (946/946), 378.65 KiB | 13.06 MiB/s, done.\n",
            "Resolving deltas: 100% (560/560), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "sys.path.append('/content')\n",
        "sys.path.append('/content/src')\n",
        "\n",
        "from pathlib import Path\n",
        "import os\n",
        "import numpy as np\n",
        "import torch as th\n",
        "from torch.utils.data import DataLoader, SequentialSampler\n",
        "from src.utils.data.dataset import read_dataset, AugmentedDataset\n",
        "from src.utils.data.collate import (\n",
        "    seq_to_ccs_graph,\n",
        "    collate_fn_factory_ccs\n",
        ")\n",
        "from src.utils.train import TrainRunner, prepare_batch\n",
        "from src.models import MSGIFSR\n"
      ],
      "metadata": {
        "id": "o-5nFJXYDjGn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess\n"
      ],
      "metadata": {
        "id": "FgfzmUFFDoJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Place dressipy files, i.e. `\n",
        "train_sessions.csv`,`train_purchases.csv`,`test_final_sessions.csv\n",
        "` in \n",
        "`\n",
        "dataset_dir\n",
        "`\n",
        "\n",
        "If\n",
        "`train_for_leaderboard`is set to `True` when calling `preprocess_dressipy`, model will be trained on the full training dataset."
      ],
      "metadata": {
        "id": "1NIKBjDCErqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.data.preprocess import preprocess_dressipy\n",
        "\n",
        "dataset_dir = Path('datasets/dressipy/')\n",
        "\n",
        "preprocess_dressipy(dataset_dir,train_for_leaderboard=False)\n",
        "#preprocess_dressipy(dataset_dir,train_for_leaderboard=True)"
      ],
      "metadata": {
        "id": "C3VZblcVDpw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35450376-dd76-4260-aa78-ea2c84a4e04e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creating training dataset\n",
            "df_purchases.shape,df_views(sessions).shape: (1000000, 3) (4743820, 3)\n",
            "size after merge  (5743820, 3)\n",
            "df_train.shape, df_test.shape: (5270397, 3) (143164, 3)\n",
            "No. of Clicks: 5412392\n",
            "No. of Items: 19553\n",
            "saving dataset to datasets/dressipy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "6sZ4vvf-DkLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def seed_torch(seed=42):\n",
        "    seed = int(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.enabled = True\n",
        "    \n",
        "seed_torch(123)\n",
        "\n",
        "def get_freer_gpu():\n",
        "    os.system('nvidia-smi -q -d Memory |grep -A4 GPU|grep Free >tmp')\n",
        "    memory_available = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
        "    # memory_available = memory_available[1:6]\n",
        "    if len(memory_available) == 0:\n",
        "        return -1\n",
        "    return int(np.argmax(memory_available))\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(get_freer_gpu())\n",
        "\n",
        "class Args:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "args = Args()\n",
        "args.dataset_dir=str(dataset_dir)\n",
        "args.embedding_dim= 256\n",
        "args.num_layers= 1\n",
        "args.feat_drop= 0.1\n",
        "args.lr= 0.1\n",
        "args.batch_size= 512\n",
        "args.epochs= 30\n",
        "args.weight_decay= 1e-4\n",
        "args.patience= 3\n",
        "args.num_workers= 4\n",
        "args.valid_split= None\n",
        "args.log_interval= 100\n",
        "args.order= 1\n",
        "args.reducer= 'mean'\n",
        "args.norm= True\n",
        "\n",
        "#opt\n",
        "args.extra=None\n",
        "args.fusion=None"
      ],
      "metadata": {
        "id": "U8bkFlGjAXsY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = th.device('cuda' if th.cuda.is_available() else 'cpu')\n",
        "dataset_dir = Path(args.dataset_dir)\n",
        "print('reading dataset')\n",
        "train_sessions, test_sessions, num_items = read_dataset(dataset_dir)\n",
        "# num_items += 5\n",
        "\n",
        "if args.valid_split is not None:\n",
        "    num_valid      = int(len(train_sessions) * args.valid_split)\n",
        "    test_sessions  = train_sessions[-num_valid:]\n",
        "    train_sessions = train_sessions[:-num_valid]\n",
        "\n",
        "train_set = AugmentedDataset(train_sessions)\n",
        "test_set  = AugmentedDataset(test_sessions)\n",
        "print(len(train_set))\n",
        "print(len(test_set))\n",
        "\n",
        "collate_fn = collate_fn_factory_ccs((seq_to_ccs_graph,), order=args.order)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_set,\n",
        "    batch_size=args.batch_size,\n",
        "    # shuffle=True,\n",
        "    # drop_last=True,\n",
        "    num_workers=args.num_workers,\n",
        "    collate_fn=collate_fn,\n",
        "    pin_memory=True,\n",
        "    sampler=SequentialSampler(train_set)\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_set,\n",
        "    batch_size=args.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=args.num_workers,\n",
        "    collate_fn=collate_fn,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "gWBhc92ZAlNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f528740f-5808-4e9b-fd15-9d435c95e728"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reading dataset\n",
            "4293287\n",
            "120553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "32cF_XUU_k1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MSGIFSR(num_items, args.dataset_dir, args.embedding_dim, args.num_layers, dropout=args.feat_drop, reducer=args.reducer, order=args.order, norm=args.norm, extra=args.extra, fusion=args.fusion, device=device)\n",
        "model = model.to(device)\n",
        "\n",
        "print(model)\n",
        "\n",
        "runner = TrainRunner(\n",
        "    args.dataset_dir,\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    device=device,\n",
        "    lr=args.lr,\n",
        "    weight_decay=args.weight_decay,\n",
        "    patience=args.patience,\n",
        ")\n",
        "\n",
        "print('start training')\n",
        "mrr, hit = runner.train(args.epochs, args.log_interval)\n",
        "print('MRR@20\\tHR@20')\n",
        "print(f'{mrr * 100:.3f}%\\t{hit * 100:.3f}%')\n"
      ],
      "metadata": {
        "id": "tq-B08FRo58q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "9XSFDUwFrKEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1NXsbnmB7NxZp2A_yHEhRXe6-lItYnJdb/view?usp=sharing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh-_jZ26WroM",
        "outputId": "ed316d69-ecc0-4f08-c624-897365adb9bc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NXsbnmB7NxZp2A_yHEhRXe6-lItYnJdb\n",
            "To: /content/pretrainedMSGIFSR.model\n",
            "100% 36.5M/36.5M [00:00<00:00, 163MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preload=False\n",
        "if preload:\n",
        "  print('Loading pretrained model...')\n",
        "  trained_for_leaderboard=False\n",
        "  with open(\"pretrainedMSGIFSR.model\",\"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "  print('Ready for evaluation.')"
      ],
      "metadata": {
        "id": "Bdwe-WITMvur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a530a2c9-55c1-4a10-d1b1-8e5ccc0259db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained model...\n",
            "Ready for evaluation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "mrr = 0\n",
        "hit = 0\n",
        "num_samples = 0\n",
        "\n",
        "ranking_df = pd.DataFrame(columns = ['item_id','rank','ground_truth'])\n",
        "with th.no_grad():\n",
        "\n",
        "    for batch in test_loader:\n",
        "        seqs, inputs, labels = prepare_batch(batch, device)\n",
        "        logits = model(*inputs)\n",
        "        batch_size   = logits.size(0)\n",
        "        num_samples += batch_size\n",
        "        topk         = logits.topk(k=100)[1]\n",
        "        labels       = labels.unsqueeze(-1)\n",
        "        hit_ranks    = torch.where(topk == labels)[1] + 1\n",
        "        hit         += hit_ranks.numel()\n",
        "        mrr         += hit_ranks.float().reciprocal().sum().item()\n",
        "        df = pd.DataFrame(\n",
        "            {\"item_id\":topk.cpu().numpy().tolist(),\n",
        "             \"ground_truth\":labels.cpu().numpy().ravel()\n",
        "            }\n",
        "        )\n",
        "        df['rank'] = df.item_id.apply(lambda x: list(range(1,len(x)+1)))\n",
        "        ranking_df = pd.concat([ranking_df,df],ignore_index=True)\n",
        "\n",
        "ranking_df = ranking_df.reset_index()\n",
        "ranking_df.columns = ['session_id','item_id','rank','ground_truth']\n",
        "ground_truth = pd.Series(ranking_df.ground_truth.values,index=ranking_df.session_id).to_dict()\n",
        "ranking_df = ranking_df.explode(['item_id','rank']).reset_index(drop=True)\n",
        "ranking_df = ranking_df.drop(\"ground_truth\",axis=1)\n",
        "print(\"MRR \",mrr/num_samples,\"Hit percentage\", hit/num_samples)"
      ],
      "metadata": {
        "id": "gaI2dvb2tqdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth[363779]"
      ],
      "metadata": {
        "id": "pJHNyFCc8AFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranking_df"
      ],
      "metadata": {
        "id": "RiFCS6W51692"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/drive/MyDrive/colab/recsys-2022/ranking_df', \"wb\") as f:\n",
        "#   pickle.dump(ranking_df, f)\n",
        "# with open('/content/drive/MyDrive/colab/recsys-2022/ground_truth', \"wb\") as f:\n",
        "#   pickle.dump(ground_truth, f)\n"
      ],
      "metadata": {
        "id": "kS_DsA7k-o1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluator = MeanReciprocitalEvaluator()\n",
        "# evaluator.get_ranking_metrics(ranking_df, ground_truth, check_if_input_correct = True)"
      ],
      "metadata": {
        "id": "1abCK_LB8PM_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}